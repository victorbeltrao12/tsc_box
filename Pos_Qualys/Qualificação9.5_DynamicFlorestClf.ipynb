{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_wfxopCnp1x"
      },
      "source": [
        "### Bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "l1AP99G_oHxu"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'%pip install aeon\\n%pip install tsfresh\\n%pip install tslearn\\n%pip install tensorflow\\n%pip install keras\\n%pip install pywavelets'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"%pip install aeon\n",
        "%pip install tsfresh\n",
        "%pip install tslearn\n",
        "%pip install tensorflow\n",
        "%pip install keras\n",
        "%pip install pywavelets\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nuvyez8anp1y"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from aeon.datasets import load_classification\n",
        "from aeon.datasets.tsc_data_lists import univariate_equal_length\n",
        "from aeon.classification.interval_based import SupervisedTimeSeriesForest, TimeSeriesForestClassifier\n",
        "\n",
        "from tsfresh import extract_features, select_features\n",
        "from tsfresh.feature_extraction import MinimalFCParameters\n",
        "\n",
        "from tslearn.preprocessing import TimeSeriesScalerMeanVariance\n",
        "from tslearn.piecewise import PiecewiseAggregateApproximation, SymbolicAggregateApproximation\n",
        "\n",
        "import pywt\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
        "from scipy.fftpack import fft\n",
        "from numba import jit\n",
        "import timeit\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctG_4yBOnp1z"
      },
      "source": [
        "### Loading data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "imNQaGTDnp10"
      },
      "outputs": [],
      "source": [
        "@staticmethod\n",
        "def load_data(dataset):\n",
        "    # LabelEncoder para labels alvo\n",
        "    le = LabelEncoder()\n",
        "\n",
        "    # Carregar conjunto de dados do repositório UCR\n",
        "    X_train, y_train = load_classification(dataset, split=\"TRAIN\")\n",
        "    X_test, y_test = load_classification(dataset, split=\"test\")\n",
        "\n",
        "    # Formatar o conjunto de dados para 2D\n",
        "    features_train = X_train.reshape(X_train.shape[0], -1)\n",
        "    features_test = X_test.reshape(X_test.shape[0], -1)\n",
        "\n",
        "    # Ajustar e transformar as labels alvo\n",
        "    target_train = le.fit_transform(y_train)\n",
        "    target_test = le.transform(y_test)\n",
        "\n",
        "    return features_train, features_test, target_train, target_test\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuvAtr74np10"
      },
      "source": [
        "### Function transform data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def choose_wavelet(X):\n",
        "    min_variance = float('inf')\n",
        "    best_wavelet = None\n",
        "    candidate_wavelets = ['db1', 'db2', 'db3', 'db4', 'db5', 'db6', 'db7', 'db8', 'db9']\n",
        "\n",
        "    for wavelet_type in candidate_wavelets:\n",
        "        _, coeffs_cD = pywt.dwt(X, wavelet_type, axis=1)\n",
        "        total_variance = np.var(coeffs_cD)\n",
        "\n",
        "        if total_variance < min_variance:\n",
        "            min_variance = total_variance\n",
        "            best_wavelet = wavelet_type\n",
        "    return str(best_wavelet)\n",
        "\n",
        "\n",
        "@jit\n",
        "def transform_data_math(X, wavelet):\n",
        "    n_sax_symbols = int(X.shape[1] / 4)\n",
        "    n_paa_segments = int(X.shape[1] / 4)\n",
        "\n",
        "    X_fft = np.abs(fft(X, axis=1))\n",
        "\n",
        "    coeffs_cA, coeffs_cD = pywt.dwt(X, wavelet=wavelet, axis=1, mode='constant')\n",
        "    X_dwt = np.hstack((coeffs_cA, coeffs_cD))\n",
        "\n",
        "    paa = PiecewiseAggregateApproximation(n_segments=n_paa_segments)\n",
        "    X_paa_ = paa.inverse_transform(paa.fit_transform(X))\n",
        "    X_paa = X_paa_.reshape(X_paa_.shape[0], -1)\n",
        "    df_PAA = pd.DataFrame(X_paa)\n",
        "    df_PAA['id'] = range(len(df_PAA))\n",
        "    \n",
        "    sax = SymbolicAggregateApproximation(n_segments=n_paa_segments, alphabet_size_avg=n_sax_symbols)\n",
        "    X_sax_ = sax.inverse_transform(sax.fit_transform(X))\n",
        "    X_sax = X_sax_.reshape(X_sax_.shape[0], -1)\n",
        "    df_SAX = pd.DataFrame(X_sax)\n",
        "    df_SAX['id'] = range(len(df_SAX))\n",
        "\n",
        "    data_X = TimeSeriesScalerMeanVariance().fit_transform(X)\n",
        "    data_X.resize(data_X.shape[0], data_X.shape[1])\n",
        "    df_X = pd.DataFrame(data_X)\n",
        "    df_X['id'] = range(len(df_X))\n",
        "\n",
        "    data_FFT = TimeSeriesScalerMeanVariance().fit_transform(X_fft)\n",
        "    data_FFT.resize(data_FFT.shape[0], data_FFT.shape[1])\n",
        "    df_FFT = pd.DataFrame(data_FFT)\n",
        "    df_FFT['id'] = range(len(df_FFT))\n",
        "\n",
        "    data_DWT = TimeSeriesScalerMeanVariance().fit_transform(X_dwt)\n",
        "    data_DWT.resize(data_DWT.shape[0], data_DWT.shape[1])\n",
        "    df_DWT = pd.DataFrame(data_DWT)\n",
        "    df_DWT['id'] = range(len(df_DWT))\n",
        "    \n",
        "    extracted_features_dict = {}\n",
        "\n",
        "    # Loop through each transformed DataFrame and extract features\n",
        "    for name, df in [('X', df_X), ('FFT', df_FFT), ('DWT', df_DWT), ('PAA', df_PAA), ('SAX', df_SAX)]:\n",
        "        features = extract_features(df, default_fc_parameters=MinimalFCParameters(), disable_progressbar=True, column_id='id')\n",
        "        extracted_features_dict[name] = features\n",
        "    return extracted_features_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "features_train, features_test, target_train, target_test = load_data('Adiac')\n",
        "wavelet = choose_wavelet(features_train)\n",
        "\n",
        "laika = transform_data_math(features_train, wavelet)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AP38ocldnp10"
      },
      "source": [
        "### AmazonForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CombinedDecisionForest:\n",
        "    def __init__(self):\n",
        "        self.clf1 = RandomForestClassifier()\n",
        "        self.clf2 = ExtraTreesClassifier()\n",
        "        self.clf3 = SupervisedTimeSeriesForest()\n",
        "        self.clf4 = TimeSeriesForestClassifier()\n",
        "        self.classifiers = [self.clf1, self.clf2, self.clf3, self.clf4]\n",
        "        self.clf_weights = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        for clf in self.classifiers:\n",
        "            clf.fit(X, y)\n",
        "\n",
        "        train_preds = [clf.predict(X) for clf in self.classifiers]\n",
        "        accuracies = [accuracy_score(y, preds) for preds in train_preds]\n",
        "\n",
        "        self.clf_weights = np.array(accuracies)\n",
        "        self.clf_weights /= np.sum(self.clf_weights)\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        probs = [clf.predict_proba(X) for clf in self.classifiers]\n",
        "        combined_probs = np.sum([prob * weight for prob, weight in zip(probs, self.clf_weights)], axis=0)\n",
        "        return combined_probs / np.sum(combined_probs, axis=1, keepdims=True)\n",
        "\n",
        "    def predict(self, X):\n",
        "        proba = self.predict_proba(X)\n",
        "        return np.argmax(proba, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'class CombinedDecisionForest:\\n    def __init__(self):\\n        self.clf1 = RandomForestClassifier()\\n        self.clf2 = ExtraTreesClassifier()\\n        self.clf3 = SupervisedTimeSeriesForest()\\n        self.clf4 = TimeSeriesForestClassifier()\\n        self.clf_weights = None\\n\\n    def fit(self, X, y):\\n        classifiers = [self.clf1, self.clf2, self.clf3, self.clf4]  # Lista de classificadores\\n\\n        for clf in classifiers:\\n            clf.fit(X, y) # Calculando os pesos com base na acurácia\\n        train_preds = [clf.predict(X) for clf in classifiers]\\n        accuracies = [accuracy_score(y, preds) for preds in train_preds]\\n\\n        self.clf_weights = np.array(accuracies) ** 4\\n        self.clf_weights /= np.sum(self.clf_weights) # Normalização dos pesos\\n\\n    def predict_proba(self, X):\\n        classifiers = [self.clf1, self.clf2, self.clf3, self.clf4]  # Lista de classificadores\\n\\n        probs = [clf.predict_proba(X) for clf in classifiers]\\n        combined_probs = np.sum([prob * weight for prob, weight in zip(probs, self.clf_weights)], axis=0)\\n\\n        return combined_probs / np.sum(combined_probs, axis=1, keepdims=True)\\n\\n    def predict(self, X):\\n        proba = self.predict_proba(X)\\n        return np.argmax(proba, axis=1)'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"class CombinedDecisionForest:\n",
        "    def __init__(self):\n",
        "        self.clf1 = RandomForestClassifier()\n",
        "        self.clf2 = ExtraTreesClassifier()\n",
        "        self.clf3 = SupervisedTimeSeriesForest()\n",
        "        self.clf4 = TimeSeriesForestClassifier()\n",
        "        self.clf_weights = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        classifiers = [self.clf1, self.clf2, self.clf3, self.clf4]  # Lista de classificadores\n",
        "\n",
        "        for clf in classifiers:\n",
        "            clf.fit(X, y) # Calculando os pesos com base na acurácia\n",
        "        train_preds = [clf.predict(X) for clf in classifiers]\n",
        "        accuracies = [accuracy_score(y, preds) for preds in train_preds]\n",
        "\n",
        "        self.clf_weights = np.array(accuracies) ** 4\n",
        "        self.clf_weights /= np.sum(self.clf_weights) # Normalização dos pesos\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        classifiers = [self.clf1, self.clf2, self.clf3, self.clf4]  # Lista de classificadores\n",
        "\n",
        "        probs = [clf.predict_proba(X) for clf in classifiers]\n",
        "        combined_probs = np.sum([prob * weight for prob, weight in zip(probs, self.clf_weights)], axis=0)\n",
        "\n",
        "        return combined_probs / np.sum(combined_probs, axis=1, keepdims=True)\n",
        "\n",
        "    def predict(self, X):\n",
        "        proba = self.predict_proba(X)\n",
        "        return np.argmax(proba, axis=1)\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train/Predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "@jit\n",
        "def train_with_meta_classifier(X_train, y_train, wavelet=None):\n",
        "    total_time = 0\n",
        "    start = timeit.default_timer()\n",
        "    extracted_features_dict = transform_data_math(X_train, wavelet=wavelet)  # Get extracted features\n",
        "    stop = timeit.default_timer()\n",
        "    total_time += stop - start\n",
        "    print('Extraction train data (seconds): ', total_time) # Get extracted features\n",
        "    # Prepare data for the meta-classifier\n",
        "    meta_features = np.hstack([extracted_features.values for extracted_features in extracted_features_dict.values()])\n",
        "    # Train a meta-classifier\n",
        "    meta_classifier = CombinedDecisionForest()\n",
        "    meta_classifier.fit(meta_features, y_train)\n",
        "\n",
        "    return meta_classifier\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "@jit\n",
        "def predict_with_meta_classifier(X_test, trained_meta_classifier, wavelet=None):\n",
        "    total_time = 0\n",
        "    start = timeit.default_timer()\n",
        "    extracted_features_dict = transform_data_math(X_test, wavelet=wavelet)  # Get extracted features\n",
        "    stop = timeit.default_timer()\n",
        "    total_time += stop - start\n",
        "    print('Extraction test data (seconds): ', total_time)\n",
        "    # Prepare data for the meta-classifier\n",
        "    meta_features_test = np.hstack([extracted_features.values for extracted_features in extracted_features_dict.values()])\n",
        "    # Train a meta-classifier\n",
        "    predictions = trained_meta_classifier.predict(meta_features_test)\n",
        "\n",
        "    return predictions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jk7b562Qnp12"
      },
      "source": [
        "### Validando o modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ZRW1Zzql88iC"
      },
      "outputs": [],
      "source": [
        "dataset_quali_list = ['Adiac', 'Beef', 'Car', 'CBF', 'Coffee', 'DiatomSizeReduction', 'ECG200', 'ECGFiveDays', 'FaceFour','GunPoint', 'Lightning2', 'Lightning7', 'MedicalImages', 'MoteStrain', 'OliveOil', 'SonyAIBORobotSurface1','SonyAIBORobotSurface2', 'SyntheticControl', 'Trace', 'TwoPatterns']\n",
        "dataset_full_list = ['Worms','FaceAll','SemgHandMovementCh2','Herring','GunPointAgeSpan','SmoothSubspace','SemgHandSubjectCh2','LargeKitchenAppliances','Plane','Fish','ScreenType','PhalangesOutlinesCorrect','CricketZ','MiddlePhalanxOutlineAgeGroup','ECG5000','Chinatown','ShapeletSim','MiddlePhalanxTW','Symbols','EOGHorizontalSignal','Ham','UMD','HouseTwenty','MiddlePhalanxOutlineCorrect','Wafer','Rock','DistalPhalanxTW','CricketY','FacesUCR','FiftyWords','Mallat','Strawberry','SwedishLeaf','ProximalPhalanxOutlineAgeGroup','MixedShapesRegularTrain','SmallKitchenAppliances','GunPointOldVersusYoung','Wine','ProximalPhalanxOutlineCorrect','WordSynonyms', 'RefrigerationDevices','Yoga','CinCECGTorso','ChlorineConcentration','ArrowHead','ToeSegmentation1','TwoLeadECG','ProximalPhalanxTW','InsectEPGSmallTrain','WormsTwoClass','PowerCons','InsectEPGRegularTrain','GunPointMaleVersusFemale','DistalPhalanxOutlineCorrect','ItalyPowerDemand','InsectWingbeatSound','BME','NonInvasiveFetalECGThorax2','CricketX','Haptics','EOGVerticalSignal','MixedShapesSmallTrain','Meat','SemgHandGenderCh2','ToeSegmentation2','NonInvasiveFetalECGThorax1','FreezerSmallTrain','OSULeaf','Earthquakes','BirdChicken','HandOutlines','BeetleFly','ACSF1','DistalPhalanxOutlineAgeGroup','FreezerRegularTrain']\n",
        "problematicos = ['Crop','EthanolLevel','ElectricDevices','FordB','ShapesAll','StarLightCurves','Phoneme', 'Computers','InlineSkate','PigAirwayPressure', 'PigCVP','FordA','MedicalImages','PigArtPressure', 'UWaveGestureLibraryX','UWaveGestureLibraryY', 'UWaveGestureLibraryZ', 'UWaveGestureLibraryAll', 'TwoPatterns']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFGKV11Rnp12",
        "outputId": "a82f769f-6037-4228-f0bf-31fe9408c66e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'accuracy_data = []\\nfor dataset_name in dataset_quali_list:\\n    # Carregue os dados de treinamento e teste\\n    features_train, features_test, target_train, target_test = load_data(dataset_name)\\n    best_wavelet = choose_wavelet(features_train)\\n\\n    meta_classifier = train_with_meta_classifier(features_train, target_train, wavelet=best_wavelet)\\n    \\n    predictions = predict_with_meta_classifier(features_test, meta_classifier, wavelet=best_wavelet)\\n    \\n    test_accuracy_meta = np.mean(predictions == target_test)\\n        \\n    accuracy_data.append({\\'Dataset Name\\': dataset_name, \\'Accuracy\\': test_accuracy_meta})\\n    \\n    print(f\"Accuracy {dataset_name}: {test_accuracy_meta}\")\\n    \\naccuracy_df = pd.DataFrame(accuracy_data)'"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"accuracy_data = []\n",
        "for dataset_name in dataset_quali_list:\n",
        "    # Carregue os dados de treinamento e teste\n",
        "    features_train, features_test, target_train, target_test = load_data(dataset_name)\n",
        "    best_wavelet = choose_wavelet(features_train)\n",
        "\n",
        "    meta_classifier = train_with_meta_classifier(features_train, target_train, wavelet=best_wavelet)\n",
        "    \n",
        "    predictions = predict_with_meta_classifier(features_test, meta_classifier, wavelet=best_wavelet)\n",
        "    \n",
        "    test_accuracy_meta = np.mean(predictions == target_test)\n",
        "        \n",
        "    accuracy_data.append({'Dataset Name': dataset_name, 'Accuracy': test_accuracy_meta})\n",
        "    \n",
        "    print(f\"Accuracy {dataset_name}: {test_accuracy_meta}\")\n",
        "    \n",
        "accuracy_df = pd.DataFrame(accuracy_data)\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "#accuracy_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "#accuracy_df.to_csv('ResultsAmazonForest_corrigido.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### DynamicAmazonClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy UMD: 0.9861111111111112\n",
            "Accuracy ToeSegmentation2: 0.8846153846153846\n",
            "Accuracy FordB: 0.7876543209876543\n",
            "Accuracy ProximalPhalanxTW: 0.8146341463414634\n",
            "Accuracy Plane: 1.0\n",
            "Accuracy Rock: 0.8\n",
            "Accuracy PigArtPressure: 0.4326923076923077\n",
            "Accuracy Wine: 0.7222222222222222\n",
            "Accuracy EOGVerticalSignal: 0.5138121546961326\n",
            "Accuracy FordA: 0.9416666666666667\n",
            "Accuracy SwedishLeaf: 0.9392\n",
            "Accuracy Ham: 0.6952380952380952\n",
            "Accuracy FiftyWords: 0.756043956043956\n",
            "Accuracy EOGHorizontalSignal: 0.5303867403314917\n",
            "Accuracy GunPointAgeSpan: 0.990506329113924\n",
            "Accuracy Meat: 0.9333333333333333\n",
            "Accuracy NonInvasiveFetalECGThorax2: 0.9297709923664123\n",
            "Accuracy Computers: 0.764\n",
            "Accuracy PowerCons: 1.0\n",
            "Accuracy SemgHandGenderCh2: 0.9666666666666667\n",
            "Accuracy FaceFour: 0.9772727272727273\n",
            "Accuracy StarLightCurves: 0.9734094220495386\n",
            "Accuracy Worms: 0.6493506493506493\n",
            "Accuracy FreezerRegularTrain: 0.9898245614035087\n",
            "Accuracy GunPoint: 0.96\n",
            "Accuracy ChlorineConcentration: 0.74140625\n",
            "Accuracy ItalyPowerDemand: 0.9689018464528668\n",
            "Accuracy WordSynonyms: 0.658307210031348\n",
            "Accuracy Lightning7: 0.7534246575342466\n",
            "Accuracy ShapeletSim: 0.9277777777777778\n",
            "Accuracy ElectricDevices: 0.7344053948904163\n",
            "Accuracy SonyAIBORobotSurface2: 0.838405036726128\n",
            "Accuracy GunPointOldVersusYoung: 1.0\n",
            "Accuracy Herring: 0.640625\n",
            "Accuracy TwoPatterns: 0.99775\n",
            "Accuracy Beef: 0.7333333333333333\n",
            "Accuracy FreezerSmallTrain: 0.864561403508772\n",
            "Accuracy InlineSkate: 0.4290909090909091\n",
            "Accuracy LargeKitchenAppliances: 0.624\n",
            "Accuracy ProximalPhalanxOutlineCorrect: 0.8797250859106529\n",
            "Accuracy ECGFiveDays: 0.9790940766550522\n",
            "Accuracy Symbols: 0.935678391959799\n",
            "Accuracy Wafer: 0.9980532121998702\n",
            "Accuracy BirdChicken: 0.9\n",
            "Accuracy UWaveGestureLibraryX: 0.8140703517587939\n",
            "Accuracy MiddlePhalanxOutlineCorrect: 0.8213058419243986\n",
            "Accuracy ECG200: 0.86\n",
            "Accuracy NonInvasiveFetalECGThorax1: 0.9139949109414758\n",
            "Accuracy ScreenType: 0.48\n",
            "Accuracy Trace: 0.98\n",
            "Accuracy DistalPhalanxTW: 0.6906474820143885\n",
            "Accuracy ShapesAll: 0.8383333333333334\n",
            "Accuracy DiatomSizeReduction: 0.9575163398692811\n",
            "Accuracy CricketX: 0.7051282051282052\n",
            "Accuracy Mallat: 0.9590618336886994\n",
            "Accuracy SemgHandSubjectCh2: 0.9244444444444444\n",
            "Accuracy SmallKitchenAppliances: 0.824\n",
            "Accuracy SonyAIBORobotSurface1: 0.8635607321131448\n",
            "Accuracy SyntheticControl: 0.9933333333333333\n",
            "Accuracy HouseTwenty: 0.8991596638655462\n",
            "Accuracy HandOutlines: 0.9135135135135135\n",
            "Accuracy DistalPhalanxOutlineCorrect: 0.7753623188405797\n",
            "Accuracy DistalPhalanxOutlineAgeGroup: 0.7553956834532374\n",
            "Accuracy SmoothSubspace: 0.9933333333333333\n",
            "Accuracy FacesUCR: 0.895609756097561\n",
            "Accuracy UWaveGestureLibraryY: 0.7319932998324958\n",
            "Accuracy Fish: 0.8628571428571429\n",
            "Accuracy UWaveGestureLibraryAll: 0.9597989949748744\n",
            "Accuracy MiddlePhalanxOutlineAgeGroup: 0.564935064935065\n",
            "Accuracy MixedShapesRegularTrain: 0.9360824742268041\n",
            "Accuracy EthanolLevel: 0.478\n",
            "Accuracy RefrigerationDevices: 0.5706666666666667\n",
            "Accuracy InsectWingbeatSound: 0.6656565656565656\n",
            "Accuracy InsectEPGRegularTrain: 1.0\n",
            "Accuracy FaceAll: 0.7988165680473372\n",
            "Accuracy TwoLeadECG: 0.8507462686567164\n",
            "Accuracy ToeSegmentation1: 0.793859649122807\n",
            "Accuracy MixedShapesSmallTrain: 0.876701030927835\n",
            "Accuracy ArrowHead: 0.7085714285714285\n",
            "Accuracy BME: 1.0\n",
            "Accuracy PhalangesOutlinesCorrect: 0.8356643356643356\n",
            "Accuracy Earthquakes: 0.7482014388489209\n",
            "Accuracy Car: 0.8\n",
            "Accuracy CinCECGTorso: 0.95\n",
            "Accuracy PigCVP: 0.3317307692307692\n",
            "Accuracy OSULeaf: 0.628099173553719\n",
            "Accuracy Lightning2: 0.7868852459016393\n",
            "Accuracy CBF: 0.9755555555555555\n",
            "Accuracy OliveOil: 0.9\n",
            "Accuracy Strawberry: 0.9702702702702702\n",
            "Accuracy ECG5000: 0.9408888888888889\n",
            "Accuracy CricketY: 0.7410256410256411\n",
            "Accuracy Haptics: 0.4805194805194805\n",
            "Accuracy MiddlePhalanxTW: 0.5714285714285714\n",
            "Accuracy UWaveGestureLibraryZ: 0.7573981016192072\n",
            "Accuracy PigAirwayPressure: 0.21634615384615385\n",
            "Accuracy InsectEPGSmallTrain: 1.0\n",
            "Accuracy Yoga: 0.8473333333333334\n",
            "Accuracy MedicalImages: 0.8092105263157895\n",
            "Accuracy Chinatown: 0.9795918367346939\n",
            "Accuracy GunPointMaleVersusFemale: 1.0\n",
            "Accuracy BeetleFly: 0.95\n",
            "Accuracy Crop: 0.772797619047619\n",
            "Accuracy MoteStrain: 0.9097444089456869\n",
            "Accuracy SemgHandMovementCh2: 0.8577777777777778\n",
            "Accuracy ProximalPhalanxOutlineAgeGroup: 0.8585365853658536\n",
            "Accuracy Coffee: 1.0\n",
            "Accuracy WormsTwoClass: 0.7142857142857143\n",
            "Accuracy CricketZ: 0.7384615384615385\n",
            "Accuracy Phoneme: 0.2689873417721519\n",
            "Accuracy Adiac: 0.7621483375959079\n",
            "Accuracy ACSF1: 0.84\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import RidgeClassifierCV\n",
        "\n",
        "accuracy_data = []\n",
        "for dataset_name in univariate_equal_length:\n",
        "    # Carregue os dados de treinamento e teste\n",
        "    features_train, features_test, target_train, target_test = load_data(dataset_name)\n",
        "    best_wavelet = choose_wavelet(features_train)\n",
        "\n",
        "    feature_extractor = CombinedDecisionForest()\n",
        "    feature_extractor.fit(features_train, target_train)\n",
        "    \n",
        "    train_features = feature_extractor.predict_proba(features_train)\n",
        "    test_features = feature_extractor.predict_proba(features_test)\n",
        "    \n",
        "    meta_model = RidgeClassifierCV(alphas=np.logspace(-3, 3, 10))\n",
        "    \n",
        "    meta_model.fit(train_features, target_train)\n",
        "    \n",
        "    predictions = meta_model.predict(test_features)\n",
        "    \n",
        "    accuracy = accuracy_score(target_test, predictions)\n",
        "        \n",
        "    accuracy_data.append({'Dataset Name': dataset_name, 'Accuracy': accuracy})\n",
        "    \n",
        "    print(f\"Accuracy {dataset_name}: {accuracy}\")\n",
        "    \n",
        "accuracy_df = pd.DataFrame(accuracy_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dataset Name</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>UMD</td>\n",
              "      <td>0.986111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ToeSegmentation2</td>\n",
              "      <td>0.884615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>FordB</td>\n",
              "      <td>0.787654</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ProximalPhalanxTW</td>\n",
              "      <td>0.814634</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Plane</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107</th>\n",
              "      <td>WormsTwoClass</td>\n",
              "      <td>0.714286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108</th>\n",
              "      <td>CricketZ</td>\n",
              "      <td>0.738462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>Phoneme</td>\n",
              "      <td>0.268987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110</th>\n",
              "      <td>Adiac</td>\n",
              "      <td>0.762148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111</th>\n",
              "      <td>ACSF1</td>\n",
              "      <td>0.840000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>112 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          Dataset Name  Accuracy\n",
              "0                  UMD  0.986111\n",
              "1     ToeSegmentation2  0.884615\n",
              "2                FordB  0.787654\n",
              "3    ProximalPhalanxTW  0.814634\n",
              "4                Plane  1.000000\n",
              "..                 ...       ...\n",
              "107      WormsTwoClass  0.714286\n",
              "108           CricketZ  0.738462\n",
              "109            Phoneme  0.268987\n",
              "110              Adiac  0.762148\n",
              "111              ACSF1  0.840000\n",
              "\n",
              "[112 rows x 2 columns]"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "accuracy_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "accuracy_df.to_csv('ModelAM_Full_Test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "w_wfxopCnp1x",
        "ctG_4yBOnp1z",
        "AP38ocldnp10",
        "48vIj_NYnp14",
        "fBZ-XYnunp15",
        "dfFvUX1YU-xH",
        "-ru7Knb6G5Ca"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "AM",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
