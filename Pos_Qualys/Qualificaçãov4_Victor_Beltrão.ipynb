{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.fftpack import fft\n",
    "from scipy.stats import norm\n",
    "import pywt\n",
    "import aeon\n",
    "from aeon.classification.distance_based import KNeighborsTimeSeriesClassifier\n",
    "import math\n",
    "from sklearn import svm, neighbors\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import xgboost as xgb\n",
    "#from sklearn.model_selection import LeaveOneOut\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#grindSearch\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    train_data = pd.read_parquet('\\DS\\Parquet_Quali\\CBF_TRAIN.parquet')\n",
    "    test_data = pd.read_parquet('\\DS\\Parquet_Quali\\CBF_TEST.parquet')\n",
    "except FileNotFoundError:\n",
    "    print(\"Ensure the Parquet files are in the correct path.\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data.drop('target', axis=1).values\n",
    "y_train = train_data['target'].values\n",
    "\n",
    "X_test = test_data.drop('target', axis=1).values\n",
    "y_test = test_data['target'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função de transformação dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sax_transform(series, w, a):\n",
    "    paa = [series[i:i + w].mean() for i in range(0, len(series), w)]\n",
    "    \n",
    "    if np.std(paa) != 0:\n",
    "        paa = (paa - np.mean(paa)) / np.std(paa)\n",
    "    else:\n",
    "        paa = paa - np.mean(paa)\n",
    "    \n",
    "    breakpoints = norm.ppf(np.linspace(0, 1, a+1)[1:-1])\n",
    "    sax_symbols = np.array(range(a))\n",
    "    sax_representation = sax_symbols[np.digitize(paa, breakpoints)]\n",
    "    \n",
    "    return sax_representation\n",
    "\n",
    "def transform_data(X, num_features=5):\n",
    "    a = 5\n",
    "    w = int(X.shape[1] / num_features)  # Ajuste do tamanho da janela baseado no número de características desejado\n",
    "    \n",
    "    X_sax = np.array([sax_transform(row, w, a) for row in X])\n",
    "    X_fft = np.abs(fft(X, axis=1))\n",
    "    \n",
    "    coeffs_cA, coeffs_cD = pywt.dwt(X, 'db4', axis=1)\n",
    "    X_dwt = np.hstack((coeffs_cA, coeffs_cD))\n",
    "    \n",
    "    X_paa = np.column_stack([X[:, i:i+2].mean(axis=1) for i in range(0, X.shape[1], 2)])\n",
    "\n",
    "    return {\n",
    "        \"TS\": X,\n",
    "        \"FFT\": X_fft,\n",
    "        \"DWT\": X_dwt,\n",
    "        \"PAA\": X_paa,\n",
    "        \"SAX\": X_sax\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "# Carregando os dados\n",
    "train, val, label, true_label = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "params = {knn, nb, rf, gbc, svc}\n",
    "# Definindo a grade de hiperparâmetros para cada classificador\n",
    "param_grids = {\n",
    "    'KNN': {\n",
    "        'knn__n_neighbors': [1, 3, 5, 7],\n",
    "        'knn__weights': ['distance'],\n",
    "        'knn__distance': ['dtw', 'ddtw','wdtw','wddtw', 'lcss', 'erp', 'msm']\n",
    "    },\n",
    "    'GaussianNB': {'var_smoothing': np.logspace(0,-9, num=100)\n",
    "    },\n",
    "    'RandomForest': {\n",
    "        'rf__n_estimators': [50, 100, 200],\n",
    "        'rf__max_depth': [None, 10, 20]\n",
    "    },\n",
    "    'GradientBoosting': {\n",
    "        'gb__n_estimators': [50, 100, 200],\n",
    "        'gb__learning_rate': [0.01, 0.1, 0.5]\n",
    "    },\n",
    "    'SVC': {\n",
    "        'svc__C': [0.1, 1, 10, 100, 1000],\n",
    "        'svc__kernel': ['linear', 'rbf', 'poly'],\n",
    "        'svc__gamma': [1, 0.1, 0.01, 0.001, 0.0001]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Função para executar a busca em grade para um classificador específico\n",
    "def run_grid_search(clf_name):\n",
    "    pipeline = classifiers[clf_name]\n",
    "    param_grid = param_grids[clf_name]\n",
    "    grid_search = GridSearchCV(pipeline, param_grid, cv=3)\n",
    "    grid_search.fit(train, label)\n",
    "    accuracy = grid_search.best_estimator_.score(val, true_label)\n",
    "    return clf_name, grid_search.best_estimator_, grid_search.best_params_, accuracy\n",
    "\n",
    "# Executando a busca em grade para cada classificador em paralelo\n",
    "results = Parallel(n_jobs=-1)(\n",
    "    delayed(run_grid_search)(clf_name) for clf_name in classifiers.keys()\n",
    ")\n",
    "\n",
    "# Imprimindo os resultados\n",
    "for clf_name, best_model, best_params, accuracy in results:\n",
    "    print(clf_name)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Best parameters:\", best_params)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seleção do modelo extrator e modelo classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_model(option, random_state):\n",
    "    if option == '1nn':\n",
    "        return neighbors.KNeighborsClassifier(metric='euclidean', n_neighbors=1)\n",
    "    elif option == '3nn':\n",
    "        return KNeighborsTimeSeriesClassifier(distance='dtw', n_neighbors=3)\n",
    "    elif option == 'svm':\n",
    "        return svm.SVC(C=10, gamma=0.01, kernel='sigmoid', probability=True)\n",
    "    elif option == 'gbc':\n",
    "        return GradientBoostingClassifier(n_estimators=100, random_state=random_state)\n",
    "    elif option == 'nb':\n",
    "        return GaussianNB()\n",
    "    elif option == 'xgb':\n",
    "        return xgb.XGBClassifier(random_state=random_state)\n",
    "    elif option == 'rd':\n",
    "        return RidgeClassifierCV(alphas=np.logspace(-3, 3, 10))\n",
    "    else:\n",
    "        return RandomForestClassifier(n_estimators=100,random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treino do modelos extrator e classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_meta_classifier(X_train, y_train, base_option='random_forest', meta_option='1nn', random_state=42, cv=3):\n",
    "    trained_models = {}  # Salvar modelos treinados para cada transformação\n",
    "    \n",
    "    X_train_transformed = transform_data(X_train)  # Transformar todo o conjunto de treino\n",
    "\n",
    "    # Treinar um modelo para cada transformação e salvar no dicionário\n",
    "    for rep, X_trans in tqdm(X_train_transformed.items(), ascii=True, desc=\"Training Base Models\"):\n",
    "        model = select_model(base_option, random_state)\n",
    "        scores = cross_val_score(model, X_trans, y_train, cv=cv)  # Calcula a acurácia em k-fold cross-validation\n",
    "        accuracy = np.mean(scores) if len(scores) > 0 else 0.0  # Calcula a média das acurácias\n",
    "        model._accuracy = accuracy  # Adiciona um atributo _accuracy ao modelo\n",
    "        model.fit(X_trans, y_train)\n",
    "        trained_models[rep] = model\n",
    "        \n",
    "    # Preparar dados para o meta-classificador\n",
    "    meta_features = []\n",
    "    weights = {}  # Dicionário para armazenar os pesos dos modelos base\n",
    "    for rep, model in trained_models.items():\n",
    "        weight = accuracy_score(y_train, model.predict(X_train_transformed[rep])) ** 4  # Calcula o peso usando a acurácia elevada à quarta potência\n",
    "        weights[rep] = weight\n",
    "    \n",
    "    for i in range(X_train.shape[0]):\n",
    "        instance_sums = np.zeros((1, len(np.unique(y_train))))  # Inicializar a soma das probabilidades para esta instância\n",
    "        for rep, model in trained_models.items():\n",
    "            proba = model.predict_proba(X_train_transformed[rep][i].reshape(1, -1))\n",
    "            # Multiplicar as probabilidades previstas pelo peso do modelo\n",
    "            instance_sums += proba * weights[rep]\n",
    "        # Normalizar as somas pelo somatório dos pesos\n",
    "        instance_sums /= np.sum(list(weights.values()))\n",
    "        meta_features.append(instance_sums.flatten())  # Estender a lista com as probabilidades normalizadas\n",
    "\n",
    "    meta_features = np.array(meta_features)\n",
    "    np.savetxt(\"meta-features-train.csv\", meta_features, delimiter=\",\")\n",
    "    \n",
    "    # Treinar o meta-classificador\n",
    "    meta_classifier = select_model(meta_option, random_state)\n",
    "    meta_classifier.fit(meta_features, y_train)\n",
    "    \n",
    "    return trained_models, meta_classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicao do meta-classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_meta_classifier(X_test, trained_base_models, trained_meta_classifier, weights=None):\n",
    "    predictions = []\n",
    "    meta_features_test = []  # Inicialize uma lista para armazenar todos os meta-recursos dos dados de teste\n",
    "    \n",
    "    for i in tqdm(range(len(X_test)), ascii=True, desc=\"Testing Instances\"):\n",
    "        x_instance = X_test[i].reshape(1, -1)\n",
    "        x_transformed = transform_data(x_instance)\n",
    "        \n",
    "        instance_sums = np.zeros((1, len(np.unique(y_train))))  # Inicializar a soma das probabilidades para esta instância\n",
    "        for rep, model in trained_base_models.items():\n",
    "            proba = model.predict_proba(x_transformed[rep][0].reshape(1, -1))  # Ajuste aqui para pegar o primeiro elemento\n",
    "            # Adicionar o peso da probabilidade prevista para cada classe à soma correspondente\n",
    "            instance_sums += proba * (weights[rep] if weights else 1)\n",
    "        # Normalizar as somas pelo somatório dos pesos\n",
    "        instance_sums /= np.sum(weights) if weights else len(trained_base_models)\n",
    "        \n",
    "        meta_feature = instance_sums.flatten().reshape(1, -1)\n",
    "        predictions.append(trained_meta_classifier.predict(meta_feature)[0])  # Adicionar a previsão à lista de previsões\n",
    "        \n",
    "        meta_features_test.append(meta_feature.flatten())  # Adicionar meta-recursos da instância atual à lista\n",
    "    \n",
    "    # Converter a lista de meta-recursos dos dados de teste em um array numpy\n",
    "    meta_features_test = np.array(meta_features_test)\n",
    "\n",
    "    # Salvar todos os meta-recursos dos dados de teste em um arquivo CSV\n",
    "    np.savetxt(\"meta-features-test.csv\", meta_features_test, delimiter=\",\")\n",
    "    \n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testando um único modelo - Random Forest como extrator e SVM como meta-classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treino\n",
    "trained_base_models, meta_classifier = train_with_meta_classifier(X_train, y_train, base_option='random_forest', meta_option='svm', random_state=42)\n",
    "\n",
    "# Teste\n",
    "predictions_test_meta = predict_with_meta_classifier(X_test, trained_base_models, meta_classifier)\n",
    "\n",
    "# Resultado\n",
    "test_accuracy_meta = np.mean(predictions_test_meta == y_test)\n",
    "\n",
    "print(f'Accuracy: {test_accuracy_meta}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testando RidgeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treino\n",
    "trained_base_models, meta_classifier = train_with_meta_classifier(X_train, y_train, base_option='random_forest', meta_option='rd', random_state=42)\n",
    "\n",
    "# Teste\n",
    "predictions_test_meta = predict_with_meta_classifier(X_test, trained_base_models, meta_classifier)\n",
    "\n",
    "# Resultado\n",
    "test_accuracy_meta = np.mean(predictions_test_meta == y_test)\n",
    "\n",
    "print(f'Accuracy: {test_accuracy_meta}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testando um único modelo - SVM como extrator e meta-classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treino\n",
    "trained_base_models, meta_classifier = train_with_meta_classifier(X_train, y_train, base_option='svm', meta_option='rd', random_state=42)\n",
    "\n",
    "# Teste\n",
    "predictions_test_meta = predict_with_meta_classifier(X_test, trained_base_models, meta_classifier)\n",
    "\n",
    "# Resultado\n",
    "test_accuracy_meta = np.mean(predictions_test_meta == y_test)\n",
    "print(f'Accuracy: {test_accuracy_meta}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treino em loop de todas as opções de classificadores disponiveis no Select Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algos = ['1nn', '3nn', 'svm', 'nb', 'gbc']\n",
    "for algo in algos:\n",
    "    \n",
    "    print(f'Meta-classificador com modelo extrator {algo.upper()}')\n",
    "    \n",
    "    # Training\n",
    "    try:\n",
    "        trained_base_models, meta_classifier = train_with_meta_classifier(X_train, y_train, base_option=algo, meta_option=algo)\n",
    "        # Testing\n",
    "        predictions_test_meta = predict_with_meta_classifier(X_test, trained_base_models, meta_classifier)\n",
    "    \n",
    "        test_accuracy_meta = np.mean(predictions_test_meta == y_test)\n",
    "        print(f'Acurácia do teste usando o meta-classificador com modelo extrator {algo}: {test_accuracy_meta}')\n",
    "    except Exception as e:\n",
    "        print(f\"Ocorreu um erro no teste com o {algo}: {e}\")\n",
    "    print(\"-------------------------------\")\n",
    "print('RF (10x)')\n",
    "for i in range(1):\n",
    "    print(f'RF: Random seed = {i}')\n",
    "    try:\n",
    "        trained_base_models, meta_classifier = train_with_meta_classifier(X_train, y_train, base_option='random_forest', meta_option='random_forest', random_state=i)\n",
    "    \n",
    "        # Testing\n",
    "        predictions_test_meta = predict_with_meta_classifier(X_test, trained_base_models, meta_classifier)\n",
    "    \n",
    "        test_accuracy = np.mean(predictions_test_meta == y_test)\n",
    "        print(f'Acurácia do teste usando seed {i}: {test_accuracy}')\n",
    "    except Exception as e:\n",
    "        print(f\"Ocorreu um erro no teste com o RF (seed {i}): {e}\")\n",
    "    print(\"-------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilizando um classificador raso com os dados extraidos do meta-classificador contra os dados puros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Teste utilizando o classificador SVM\n",
    "meta_attrib_train = np.loadtxt(\"meta-features-train.csv\", delimiter=\",\")\n",
    "meta_attrib_test = np.loadtxt(\"meta-features-test.csv\", delimiter=\",\")\n",
    "\n",
    "clf = svm.SVC(probability=True)\n",
    "clf.fit(meta_attrib_train, y_train)\n",
    "y_hat = clf.predict(meta_attrib_test)\n",
    "test_accuracy_meta = np.mean(y_hat == y_test)\n",
    "print(f\"accuracy: {test_accuracy_meta}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_2 = svm.SVC(probability=True)\n",
    "clf_2.fit(X_train, y_train)\n",
    "y_hat_ = clf_2.predict(X_test)\n",
    "test_accuracy_meta_2 = np.mean(y_hat_ == y_test)\n",
    "print(f\"accuracy: {test_accuracy_meta_2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gráfico das diferenças de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y1 = y_hat  # depois da transformação\n",
    "y2 = y_test  \n",
    "\n",
    "z1 = y_hat_ #antes da transformação\n",
    "z2 = y_test\n",
    "\n",
    "#suavizar os dados do gráfico\n",
    "window_size = 50\n",
    "y1_smoothed = pd.Series(y1).rolling(window=window_size).mean()\n",
    "y2_smoothed = pd.Series(y2).rolling(window=window_size).mean()\n",
    "z1_smoothed = pd.Series(z1).rolling(window=window_size).mean()\n",
    "z2_smoothed = pd.Series(z2).rolling(window=window_size).mean()\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(15, 5), layout='constrained')\n",
    "\n",
    "# Conjunto de validação do classificador\n",
    "axs[0].set_title('Antes da transformação')\n",
    "axs[0].plot(z1_smoothed, label='Treino')\n",
    "axs[0].plot(z2_smoothed, label='Teste')\n",
    "axs[0].set_xlabel('Tempo (s)')\n",
    "axs[0].set_ylabel('Treino')\n",
    "axs[0].grid(True)\n",
    "\n",
    "# Conjunto de validação do meta-classificador\n",
    "axs[1].set_title('Depois da transformação')\n",
    "axs[1].plot(y1_smoothed, label='Treino')\n",
    "axs[1].plot(y2_smoothed, label='Teste')\n",
    "axs[1].set_xlabel('Tempo (s)')\n",
    "axs[1].set_ylabel('Treino')\n",
    "axs[1].grid(True)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = y_hat  # meta-classificador\n",
    "w2 = y_hat_ #classificação\n",
    "\n",
    "# Suavizar os dados do gráfico\n",
    "window_size = 90\n",
    "w1_smoothed = pd.Series(w1).rolling(window=window_size).mean()\n",
    "w2_smoothed = pd.Series(w2).rolling(window=window_size).mean()\n",
    "\n",
    "# Plotar os dados\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(w1_smoothed, label='w1 (Classificação usando meta-caracteristicas)')\n",
    "plt.plot(w2_smoothed, label='w2 (classificação utilizando dados brutos)')\n",
    "plt.xlabel('Tempo (s)')\n",
    "plt.ylabel('Valores suavizados')\n",
    "plt.title('Comparação entre os resultados de um SVM')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
